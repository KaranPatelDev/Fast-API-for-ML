# ðŸ› Advanced FastAPI Debugging Techniques

## ðŸ“Š Structured Logging

### Conceptual Understanding

Structured logging represents a paradigm shift from traditional plain-text logging to machine-readable, searchable log formats. Unlike conventional logging where information is embedded in unstructured text, structured logging organizes data into key-value pairs, typically in JSON format. This approach transforms logs from human-readable narratives into structured data that can be efficiently processed, filtered, and analyzed by both humans and machines.

The fundamental principle behind structured logging is **consistency and context preservation**. Every log entry follows a predictable schema, making it possible to query logs like a database. This consistency enables powerful log aggregation tools, real-time monitoring systems, and automated alerting mechanisms.

### Theoretical Foundations

**1. Log Levels and Hierarchy**
- DEBUG: Detailed diagnostic information for development
- INFO: General operational information
- WARNING: Potentially harmful situations
- ERROR: Error events that allow application to continue
- CRITICAL: Serious errors that may cause application termination

**2. Context Propagation**
Request context flows through the entire application lifecycle, ensuring all related log entries share common identifiers (request IDs, user IDs, session tokens).

**3. Structured Data Benefits**
- **Searchability**: Query specific fields across millions of log entries
- **Aggregation**: Group and analyze patterns in application behavior
- **Alerting**: Create precise rules based on structured fields
- **Compliance**: Maintain audit trails with consistent data structure

### Implementation Strategies

**Context Variables for Async Applications**
```python
from contextvars import ContextVar
import uuid

# Global context variables
request_id_var: ContextVar[str] = ContextVar('request_id')
user_id_var: ContextVar[str] = ContextVar('user_id')

# Middleware sets context at request start
request_id_var.set(str(uuid.uuid4()))
```

**Log Enrichment Patterns**
```python
# Base context that appears in all logs
base_context = {
    "service": "user_api",
    "version": "1.0.0",
    "environment": "production"
}

# Request-specific context
request_context = {
    "request_id": "req_123",
    "user_id": "user_456",
    "endpoint": "/users/create"
}
```

---

## ðŸš¨ Exception Handling

### Conceptual Framework

Exception handling in FastAPI extends beyond simple try-catch blocks to encompass a comprehensive error management strategy. The goal is to create a resilient system that gracefully handles all types of failures while providing meaningful feedback to clients and maintaining system stability.

**Error Categorization Philosophy:**
1. **Expected Errors**: Business logic violations, validation failures
2. **Unexpected Errors**: System failures, external service outages
3. **Security Errors**: Authentication failures, authorization violations
4. **Infrastructure Errors**: Database connectivity, network timeouts

### Exception Hierarchy Design

**Domain-Driven Exception Design**
```python
# Base exception with rich context
class BaseAPIException(Exception):
    def __init__(self, message: str, status_code: int, error_code: str, details: dict):
        self.message = message
        self.status_code = status_code
        self.error_code = error_code
        self.details = details
```

**Business Logic Exceptions**
- Represent domain rule violations
- Provide specific error codes for client handling
- Include context about what went wrong and why

**Infrastructure Exceptions**
- Handle external dependencies failures
- Implement retry mechanisms and circuit breakers
- Provide fallback responses when possible

### Error Response Standards

**Consistent Error Schema**
```json
{
    "error": {
        "code": "VALIDATION_ERROR",
        "message": "User-friendly error description",
        "details": {
            "field": "email",
            "constraint": "format",
            "provided_value": "invalid-email"
        },
        "timestamp": "2023-12-01T10:30:45Z",
        "trace_id": "req_123456789"
    }
}
```

**Error Context Preservation**
- Maintain request tracing through error flows
- Log errors with full context for debugging
- Sanitize sensitive information before client response

### Advanced Exception Patterns

**Circuit Breaker Pattern**
```python
class CircuitBreaker:
    def __init__(self, failure_threshold=5, recovery_timeout=60):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half-open
```

**Retry with Exponential Backoff**
```python
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10),
    retry=retry_if_exception_type(ExternalServiceException)
)
async def call_external_service():
    # Implementation with automatic retries
    pass
```

---

## ðŸ› ï¸ API Testing Tools (Postman/curl)

### Testing Methodology

API testing encompasses multiple dimensions beyond simple request-response validation. Comprehensive testing evaluates functionality, performance, security, and reliability across various scenarios and conditions.

**Testing Pyramid for APIs:**
1. **Unit Tests**: Individual endpoint logic
2. **Integration Tests**: API + Database interactions
3. **Contract Tests**: API specification compliance
4. **End-to-End Tests**: Complete user workflows
5. **Performance Tests**: Load and stress testing
6. **Security Tests**: Vulnerability assessment

### Postman Advanced Concepts

**Collection Architecture**
Postman collections should be organized hierarchically with shared authentication, environment variables, and reusable test scripts. The architecture supports:
- **Inheritance**: Child requests inherit parent folder settings
- **Variables**: Environment, collection, and global scopes
- **Pre-request Scripts**: Dynamic data generation and setup
- **Test Scripts**: Validation and data extraction

**Dynamic Testing Workflows**
```javascript
// Pre-request script for dynamic data
const timestamp = Date.now();
pm.environment.set("unique_email", `test${timestamp}@example.com`);

// Chain requests using extracted data
pm.test("Extract user ID", function() {
    const responseJson = pm.response.json();
    pm.environment.set("created_user_id", responseJson.user_id);
});
```

**Advanced Assertions**
```javascript
// Schema validation
pm.test("Response matches schema", function() {
    const schema = {
        "type": "object",
        "required": ["id", "name", "email"],
        "properties": {
            "id": {"type": "integer"},
            "name": {"type": "string"},
            "email": {"type": "string", "format": "email"}
        }
    };
    pm.response.to.have.jsonSchema(schema);
});

// Performance testing
pm.test("Response time acceptable", function() {
    pm.expect(pm.response.responseTime).to.be.below(500);
});
```

### curl Testing Strategies

**Scriptable Testing**
curl excels in automated testing scenarios where programmatic control is needed. Shell scripts can orchestrate complex testing workflows:

```bash
# Test data preparation
generate_test_data() {
    echo '{"name":"Test User","email":"test'$(date +%s)'@example.com"}'
}

# Response validation
validate_response() {
    local response="$1"
    local expected_status="$2"
    
    if echo "$response" | jq -e '.user_id' > /dev/null; then
        echo "âœ“ Response contains user_id"
    else
        echo "âœ— Missing user_id in response"
        return 1
    fi
}
```

**Performance Benchmarking**
```bash
# Concurrent request testing
seq 1 100 | xargs -n1 -P10 -I{} curl -s -w "%{time_total}\n" \
    http://localhost:8000/api/endpoint -o /dev/null
```

### Testing Automation Patterns

**Data-Driven Testing**
```python
test_cases = [
    {"input": {"age": 25}, "expected_status": 200},
    {"input": {"age": -1}, "expected_status": 422},
    {"input": {"age": "invalid"}, "expected_status": 422}
]

for case in test_cases:
    response = client.post("/validate", json=case["input"])
    assert response.status_code == case["expected_status"]
```

**Contract Testing**
Ensures API implementation matches specification:
```python
def test_openapi_compliance():
    spec = get_openapi_spec()
    for endpoint in spec.paths:
        response = client.get(endpoint)
        validate_response_against_schema(response, spec)
```

---

## âš™ï¸ Development Mode Configurations

### Environment Strategy

Development mode configuration creates an optimized environment for rapid development, debugging, and testing. The strategy involves multiple configuration layers that adapt application behavior based on the deployment environment.

**Configuration Hierarchy:**
1. **Default Values**: Sensible defaults for development
2. **Environment Files**: `.env.development`, `.env.staging`, `.env.production`
3. **Environment Variables**: Runtime overrides
4. **Command Line Arguments**: Temporary overrides

### Feature Flag Architecture

Development configurations often include feature flags that enable or disable functionality based on environment:

```python
class FeatureFlags:
    enable_debug_toolbar: bool = False
    enable_sql_logging: bool = False
    enable_request_logging: bool = True
    enable_performance_metrics: bool = False
    enable_mock_external_services: bool = False
```

### Development Server Optimizations

**Hot Reloading Strategy**
- **File Watching**: Monitor source code changes
- **Selective Reloading**: Only reload affected modules
- **State Preservation**: Maintain database connections across reloads
- **Error Recovery**: Continue running after non-fatal errors

**Debug Mode Features**
- **Enhanced Error Pages**: Full stack traces with source code
- **Interactive Debugger**: Web-based debugging interface
- **Request/Response Logging**: Detailed HTTP transaction logs
- **Performance Profiling**: Built-in performance monitoring

### Configuration Management

**Environment Isolation**
```python
class Settings:
    @property
    def database_url(self) -> str:
        if self.environment == "testing":
            return "sqlite:///./test.db"
        elif self.environment == "development":
            return f"postgresql://dev:dev@localhost/dev_db"
        else:
            return os.getenv("DATABASE_URL")
```

**Security Considerations**
- **Secret Management**: Never commit secrets to version control
- **Environment Separation**: Different keys for different environments
- **Access Controls**: Limit access to production configurations

### Development Workflow Integration

**IDE Integration**
- **Debugger Configuration**: Attach debugger to running application
- **Code Completion**: Type hints and API documentation
- **Error Highlighting**: Real-time syntax and type checking

**Container Development**
Docker-based development ensures consistency across team members:
```dockerfile
# Multi-stage build for development
FROM python:3.11-slim as development
COPY requirements-dev.txt .
RUN pip install -r requirements-dev.txt
CMD ["python", "-m", "uvicorn", "main:app", "--reload", "--host", "0.0.0.0"]
```

**Monitoring and Observability**
Development environments benefit from built-in observability:
- **Health Checks**: Application and dependency status
- **Metrics Collection**: Request rates, response times, error rates
- **Distributed Tracing**: Request flow across services
- **Log Aggregation**: Centralized log collection and analysis

### Best Practices

**Configuration Principles**
1. **Explicit over Implicit**: Make configuration choices obvious
2. **Environment Parity**: Minimize differences between environments
3. **Externalized Config**: Store config in environment variables
4. **Validation**: Validate configuration on startup
5. **Documentation**: Document all configuration options

**Development Productivity**
- **Fast Feedback Loops**: Quick error detection and resolution
- **Comprehensive Logging**: Detailed information for debugging
- **Easy Testing**: Simple test execution and debugging
- **Flexible Configuration**: Easy switching